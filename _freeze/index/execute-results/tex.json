{
  "hash": "77e6858c5f855e33f5dcfad534ae593e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"My wonderful paper\"\nabstract: \"This is the abstract\"\nbibliography: references.bib\ndocumentclass: jds\nformat: pdf\npreamble: >\n  \\usepackage{amsfonts,amsmath,amssymb,amsthm}\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell .hidden}\n\n```{.r .cell-code .hidden}\nknitr::opts_chunk$set(echo = FALSE)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.4     v readr     2.1.5\nv forcats   1.0.0     v stringr   1.5.1\nv ggplot2   3.5.1     v tibble    3.2.1\nv lubridate 1.9.3     v tidyr     1.3.1\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(patchwork)\nlibrary(MASS)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'MASS'\n\nThe following object is masked from 'package:patchwork':\n\n    area\n\nThe following object is masked from 'package:dplyr':\n\n    select\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(ggh4x)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'ggh4x'\n\nThe following object is masked from 'package:ggplot2':\n\n    guide_axis_logticks\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\npm10 <- read_csv(here::here(\"data\", \"pm10.csv\")) |> \n  filter(!is.na(pm10)) |>    \n  mutate(season = as.factor(season))  \n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 3288 Columns: 6\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr  (1): season\ndbl  (4): mortality, pm10, temp, dewpt\ndate (1): date\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n\n# Introduction\n\nIn this paper, a concept called analysis plan is proposed to describe the logical structure of a data analysis. An analysis plan is a set of analysis steps plus their expected outcomes. It is a formal representation of the analysis process and can be used to guide the analysis process, to communicate and compare the analysis process to others, and to evaluate the analysis process. The concept of analysis plan is illustrated with examples and the implications of the concept for data analysis practice is discussed.\n\nThe analysis plan described in this paper should be differentiated from the pre-specifies analysis plan document often used in biostatistics to specifies the hypothesis, data collection mechanism, statistical procedures etc of randomized experiments. \n\n\n# Analysis plan\n\ndescribe/ define what analysis plan is \n\nanalysis plan and outcome plan \n\nanalysis plan as unit tests to divide the \"result universe\", which allows us to answer questions like:\n\n- how would the results change if the value of a unit test change\n- whether our outcome expectation aligns with the plan expectation, meaning whether \"it is possible for the combination of plan expectations to produce the outcome expectation\"\n\n# Examples\n\n## A toy example\n\n## Linear regression\n\nConsider a linear regression model to study the effect of PM10 on mortality (provide context of using PM10 to study mortality). From the literature, analysts may expect a significant PM10 coefficient in the linear model from the literature. This is the outcome expectation: p-value of PM10 coefficient is less than 0.05. There are multiple factors that can affect the outcome expectation of this analysis, for example, 1) sample size, 2) model specification, and 3) correlation structure between variables. Temperature is often an important confounder to consider in such study (add reference). \n\nTo construct the result universe, we can simulate datasets with different configerations of the above factors. Here, sample sizes of 50, 100, 500, and 1000 are considered. Two model specifications are included: 1) linear model with PM10 as the only covariate ($\\text{mortality} \\sim \\text{PM10}$), 2) linear model with PM10 and temperature as covariates ($\\text{mortality} \\sim \\text{PM10} + \\text{temp}$. A grid-based approach is used to simulate correlation structure. Reasonable ranges of correlation between the three variables are\n\n\\begin{align*}\n\\text{cor}(\\text{mortality}, \\text{PM10}) &\\in [-0.01, 0] \\\\ \n\\text{cor}(\\text{mortality}, \\text{temperature}) &\\in [-0.6, -0.2] \\\\ \\text{cor}(\\text{PM10}, \\text{temperature}) &\\in [0.2, 0.6] \n\\end{align*}\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Generate correlation matrices \ncorr_grid <- expand.grid(seq(-0.01, -0.001, by = 0.001), \n                         seq(-0.6, -0.2, 0.05), seq(0.2, 0.6, 0.05))  \n\n# Function to compute correlation matrix for each combination \ngen_corr_mtx <- function(r1, r2, r3) {   \n  cor_matrix <- matrix(c(1, r1, r2,                          \n                         r1, 1, r3,                          \n                         r2, r3, 1), nrow = 3, byrow = TRUE)          \n  # Store the matrix in the list   \n  if (all(eigen(cor_matrix)$values > 0)) return(cor_matrix) \n  }  \n\n# Plan for parallel processing\ncorr_mtx <- lapply(1:nrow(corr_grid), function(i) {   \n  gen_corr_mtx(corr_grid[i, 1], corr_grid[i, 2], corr_grid[i, 3]) }) \ncorr_mtx <- corr_mtx[map_lgl(corr_mtx, ~!is.null(.x))]  \nsample_size <- c(50, 100, 500, 1000) \nmodel <- c(\"mortality ~ pm10 + temp\", \"mortality ~ pm10\") |> map(as.formula) \n\ngenerate_data <- function(n, mtx, seed = 123) {   \n  mu <- c(0, 0, 0)   \n  data <- mvrnorm(n, mu, mtx, empirical = TRUE)   \n  U <- pnorm(data, mean = 0, sd = 1)   \n  set.seed(seed)      \n  tibble(mortality = qpois(U[,1], 182), # assume distribution\n         pm10 = qnorm(U[,2], mean = 26, sd = 12),           \n         temp = qnorm(U[,3], mean = 55, sd = 16))   \n  }  \n\nres <- tibble(corr_mtx = corr_mtx) |> \n  mutate(id = row_number()) |> \n  crossing(sample_size, model) |> \n  rowwise() |>   \n  mutate(data = list(generate_data(n = sample_size, mtx = corr_mtx)),          \n         fit = list(summary(lm(model, data))$coefficients))  \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndt <- res |>   \n  mutate(     \n    p_value = fit[2,4],     \n    coef = fit[2,1],     \n    xy_correlation = as.numeric(corr_mtx[1, 2]),     \n    xz_correlation = as.numeric(corr_mtx[1, 3]),     \n    yz_correlation = as.numeric(corr_mtx[2, 3]),     \n    fml = deparse(model) |> as.factor(),     \n    expect = ifelse(p_value < 0.05, 1, 0) |> as.factor(),     \n    ) |>    \n  ungroup() \n\ncode_tbl <- crossing(V1 = c(\"signifpm10\", NA),           \n                     V2 = c(\"smallsample\", NA), \n                     V3 = c(\"withtemp\", NA)) |>      \n  mutate(col1 = paste0(V1,\"_\", V2, \"_\", V3))   \n\nlookup_tbl <- tibble(   \n  value = crossing(x = c(1, 0), y = c(1, 0), z = c(1, 0)) |>      \n    mutate(col = paste0(x,\"_\", y, \"_\", z)) |> \n    arrange(-x, -y, -z) |>      \n    pull(col),   \n  plan1 = unique(code_tbl$col1) )  \n\ndt2 <- dt |>    \n  mutate(T1 = ifelse(sample_size < 200, 1, 0),          \n         T2 = ifelse(fml == \"mortality ~ pm10 + temp\", 1, 0),          \n         pp1 = paste0(expect, \"_\", T1, \"_\", T2),) |>    \n  left_join(lookup_tbl, by = c(\"pp1\" = \"value\"))      \n\np0 <- dt |> ggplot() +   \n  geom_point(aes(x = p_value , y = coef), color = \"grey\", size = 0.5) +  \n  labs(x = \"p-value\", y = \"coefficient\") +   \n  scale_color_brewer(palette = \"Dark2\", direction = -1) +   \n  theme_bw() +    \n  theme(aspect.ratio = 1, \n        panel.grid.minor = element_blank()) \n\np0 + \n  geom_point(aes(x = p_value , y = coef), size = 0.5) +  \n  facet_grid(as.character(model) ~ sample_size) +    \n  labs(title = \"Coefficient vs. p-value\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/unnamed-chunk-2-1.pdf){fig-pos='H'}\n:::\n:::\n\n::: {#cell-fig-result-universe .cell}\n\n```{.r .cell-code .hidden}\ndf0 <-  dt |> filter(sample_size == 500, xy_correlation == -0.005, \n                     between(xz_correlation, -0.46, -0.43),\n                     yz_correlation == 0.4) |> arrange(expect)\n#df2 <- df0 |> filter(fml == \"mortality ~ pm10 + temp\") # test for model spec\n\np1 <- p0 + \n  geom_point(aes(x = p_value , y = coef, color = expect), size = 0.5) +  \n  labs(title = \"Coefficient vs. p-value\") + \n  theme(legend.position = 'none')\n\np3 <- p0 + \n  geom_point(aes(x = p_value, y = coef, color = fml), size = 0.5) +\n  labs(title = \"Effect of adding temperature\") \n\ndf00 <-  dt |> filter(xy_correlation == -0.005, \n                     between(xz_correlation, -0.46, -0.43),\n                     yz_correlation == 0.4) |> arrange(expect)\ndf4 <- df00 |> filter((fml == \"mortality ~ pm10 + temp\"))\n\np5 <- p0 + \n  geom_point(data = df4, aes(x = p_value, y = coef, color = expect), size = 1) +\n  geom_path(data = df4, aes(x = p_value, y = coef), color = \"black\",\n            arrow = arrow(type = \"open\", angle = 30, length = unit(0.1, \"inches\"))) +\n  scale_color_brewer(palette = \"Dark2\", direction = -1) +\n  labs(title = \"Effect of sample size\") \n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n(p1 | p3 | p5) + plot_annotation(tag_levels = \"a\") + \n  plot_layout(guides = 'collect') &\n  theme(legend.position = 'bottom') \n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/fig-result-universe-1.pdf){#fig-result-universe fig-pos='H'}\n:::\n:::\n\n\n@fig-result-universe shows that result universe of the linear regression model with a) colored by whether the p-value of PM10 is significant (less than 0.05), b) highlighting the effect of adding temperature to the model for a fixed correlation structure, and c) highlighting the effect of increasing sample size.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}